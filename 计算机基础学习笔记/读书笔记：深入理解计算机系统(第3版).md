---
title: 读书笔记：深入理解计算机系统(第3版)
date: 2020-07-20 15:05:00
tags: 读书笔记
categories: 计算机底层原理
---

(注1：这本书挺经典的，在不方便学前端的时候[上班摸鱼的时候]或者学习累了的时候看一看吧，希望未来3年内能够大体看完一遍吧)

(注2：这本书很厚，但是没有关系，反正我也不赶时间，有时间的时候，想起来的时候，就去看个一节两节的，慢慢的就能水滴石穿了，最终有看完的那一天了。记录一下时间：今天是2020年7月20日。)

(注3：发现一本通俗读物《计算机的心智:操作系统之哲学原理》，挺不错的，可以交叉着看一看)

# 前言

本书（简称CS：APP）的主要读者是计算机科学家、计算机工程师，以及那些想通过学习计算机系统的内在运作而能够写出更好程序的人。

我们的目的是解释所有计算机系统的本质概念，并向你展示这些概念是如何实实在在地影响应用程序的正确性、性能和实用性的。其他的系统类书籍都是从构建者的角度来写的，讲述如何实现硬件或系统软件，包括操作系统、编译器和网络接口。而本书是从程序员的角度来写的，讲述应用程序员如何能够利用系统知识来编写出更好的程序。当然，学习一个计算机系统应该做些什么，是学习如何构建一个计算机系统的很好的出发点，所以，对于希望继续学习系统软硬件实现的人来说，本书也是一本很有价值的介绍性读物。大多数系统书籍还倾向于重点关注系统的某一个方面，比如：硬件架构、操作系统、编译器或者网络。本书则以程序员的视角统一覆盖了上述所有方面的内容。

如果你研究和领会了这本书里的概念，你将开始成为极少数的“牛人”，这些“牛人”知道事情是如何运作的，也知道当事情出现故障时如何修复。你写的程序将能够更好地利用操作系统和系统软件提供的功能，对各种操作条件和运行时参数都能正确操作，运行起来更快，并能避免出现使程序容易受到网络攻击的缺陷。同时，你也要做好更深入探究的准备，研究像编译器、计算机体系结构、操作系统、嵌入式系统、网络互联和网络安全这样的高级题目。

## 读者应具备的背景知识

本书的重点是执行x86-64机器代码的系统。对英特尔及其竞争对手而言，x86-64是他们自1978年起，以8086微处理器为代表，不断进化的最新成果。按照英特尔微处理器产品线的命名规则，这类微处理器俗称为"x86"。随着半导体技术的演进，单芯片上集成了更多的晶体管，这些处理器的计算能力和内存容量有了很大的增长。在这个过程中，它们从处理16位字，发展到引入1A32处理器处理32位字，再到最近的x86-64处理64位字。

我们考虑的是这些机器如何在Linux操作系统上运行C语言程序。Linux是众多继承自最初由贝尔实验室开发的Unix的操作系统中的一种。这类操作系统的其他成员包括Solaris，FreeBSD和MacOS X。近年来，由于Posix和标准Unix规范的标准化努力，这些操作系统保持了高度兼容性。因此，本书内容几乎直接适用于这些“类Unix"操作系统。

文中包含大量已在Linux系统上编译和运行过的程序示例。我们假设你能访问一台这样的机器，并且能够登录，做一些诸如切换目录之类的简单操作。如果你的计算机运行的是Microsoft Windows系统，我们建议你选择安装一个虚拟机环境（例如VirtualBox或者VMWare），以便为一种操作系统（客户（S）编写的程序能在另一种系统（宿主OS）上运行。

我们还假设你对C和C++有一定的了解。如果你以前只有Java经验，那么你需要付出更多的努力来完成这种转换，不过我们也会帮助你。Java和C有相似的语法和控制语句。不过，有一些C语言的特性（特别是指针、显式的动态内存分配和格式化1/0）在Java中都是没有的。

所幸的是，C是一个较小的语言，在Brian Kernighan和Dennis Ritchie经典的"K8R"文献中得到了清晰优美的描述。无论你的编程背景如何，都应该考虑将K&R作为个人系统藏书的一部分。如果你只有使用解释性语言的经验，如Python，Ruby或Perl，那么在使用本书之前，需要花费一些时间来学习C。

本书的前几章揭示了C语言程序和它们相对应的机器语言程序之间的交互作用。机器语言示例都是用运行在x86-64处理器上的GNU GCC编译器生成的。我们不需要你以前有任何硬件、机器语言或是汇编语言编程的经验。

![](读书笔记：深入理解计算机系统(第3版)/01.png)

## 如何阅读此书

从程序员的角度学习计算机系统是如何工作的会非常有趣，主要是因为你可以主动地做这件事情。无论何时你学到一些新的东西，都可以马上试验并且直接看到运行结果。事实上，我们相信学习系统的唯一方法就是做（do）系统，即在真正的系统上解决具体的问题，或是编写和运行程序。

这个主题观念贯穿全书。当引入一个新概念时，将会有一个或多个练习题紧随其后，你应该马上做一做来检验你的理解。这些练习题的解答在每章的末尾。当你阅读时，尝试自己来解答每个问题，然后再查阅答案，看自己的答案是否正确。除第1章外，每章后面都有难度不同的家庭作业。对每个家庭作业题，我们标注了难度级别：

![](读书笔记：深入理解计算机系统(第3版)/02.png)

文中每段代码示例都是由经过GCC编译的C程序直接生成并在Linux系统上进行了测试，没有任何人为的改动。当然，你的系统上GCC的版本可能不同，或者根本就是另外一种编译器，那么可能生成不一样的机器代码，但是整体行为表现应该是一样的。所有的源程序代码都可以从csapp.cs.cmu.edu上的CS:APP主页上获取。在本书中，源程序的文件名列在两条水平线的右边，水平线之间是格式化的代码。比如，图1中的程序能在code/intro/目录下的hello.c文件中找到。当遇到这些示例程序时，我们鼓励你在自己的系统上试着运行它们。

![](读书笔记：深入理解计算机系统(第3版)/03.png)

为了避免本书体积过大、内容过多，我们添加了许多网络旁注（Web aside），包括一些对本书主要内容的补充资料。本书中用CHAP：TOP这样的标记形式来引用这些旁注，这里CHAP是该章主题的缩写编码，而TOP是涉及的话题的缩写编码。例如，网络旁注DATA：BOOL包含对第2章中数据表示里面有关布尔代数内容的补充资料；而网络旁注ARCH：VLOG包含的是用Verilog硬件描述语言进行处理器设计的资料，是对第4章中处理器设计部分的补充。所有的网络旁注都可以从CS:APP的主页上获取。

![](读书笔记：深入理解计算机系统(第3版)/04.png)

## 本书概述

![](读书笔记：深入理解计算机系统(第3版)/05.png)

## 本版新增内容

![](读书笔记：深入理解计算机系统(第3版)/06.png)

## 经过课堂验证的实验练习(9个实验很重要)

![](读书笔记：深入理解计算机系统(第3版)/07.png)

# 第1章：计算机系统漫游

计算机系统是由硬件和系统软件组成的，它们共同工作来运行应用程序。虽然系统的具体实现方式随着时间不断变化，但是系统内在的概念却没有改变。所有计算机系统都有相似的硬件和软件组件，它们又执行着相似的功能。一些程序员希望深入了解这些组件是如何工作的以及这些组件是如何影响程序的正确性和性能的，以此来提高自身的技能。本书便是为这些读者而写的。

现在就要开始一次有趣的漫游历程了。如果你全力投身学习本书中的概念，完全理解底层计算机系统以及它对应用程序的影响，那么你会步上成为为数不多的“大牛”的道路。

> 唉，我好想当个大牛啊。但是我现在的技术水平估计连找个工作都找不到。

你将会学习一些实践技巧，比如如何避免由计算机表示数字的方式引起的奇怪的数字错误。你将学会怎样通过一些小窍门来优化自己的C代码，以充分利用现代处理器和存储器系统的设计。你将了解编译器是如何实现过程调用的，以及如何利用这些知识来避免缓冲区溢出错误带来的安全漏洞，这些弱点给网络和因特网软件带来了巨大的麻烦。你将学会如何识别和避免链接时那些令人讨厌的错误，它们困扰着普通的程序员。你将学会如何编写自己的Unix shell、自己的动态存储分配包，甚至于自己的Web服务器。你会认识并发带来的希望和陷阱，这个主题随着单个芯片上集成了多个处理器核变得越来越重要。

在Kernighan和Ritchie的关于C编程语言的经典教材中，他们通过图1-1中所示的hello程序来向读者介绍C，尽管hel10程序非常简单，但是为了让它实现运行，系统的每个主要组成部分都需要协调工作。从某种意义上来说，本书的目的就是要帮助你了解当你在系统上执行hello程序时，系统发生了什么以及为什么会这样。

![](读书笔记：深入理解计算机系统(第3版)/08.png)

我们通过跟踪hell0程序的生命周期来开始对系统的学习-从它被程序员创建开始，到在系统上运行，输出简单的消息，然后终止。我们将沿着这个程序的生命周期，简要地介绍一些逐步出现的关键概念、专业术语和组成部分。后面的章节将围绕这些内容展开。

## 信息就是位+上下文

hello程序的生命周期是从一个源程序（或者说源文件）开始的，即程序员通过编辑器创建并保存的文本文件，文件名是he1lo.c。源程序实际上就是一个由值0和1组成的位（又称为比特）序列，8个位被组织成一组，称为**字节**。每个字节表示程序中的某些文本字符。

大部分的现代计算机系统都使用ASCII标准来表示文本字符，这种方式实际上就是用一个唯一的单字节大小的整数值来表示每个字符。比如，图1-2中给出了hello.c程序的ASCII码表示。

![](读书笔记：深入理解计算机系统(第3版)/09.png)

hello.c程序是以字节序列的方式储存在文件中的。每个字节都有一个整数值，对应于某些字符。例如，第一个字节的整数值是35，它对应的就是字符“#”，第二个字节的整数值为105，它对应的字符是"i'，依此类推。注意，每个文本行都是以一个看不见的换行符'\n'来结束的，它所对应的整数值为10，像hello.c这样只由ASCII字符构成的文件称为**文本文件**，所有其他文件都称为**二进制文件**。

[文本文件和二进制文件到底有什么区别？](https://blog.csdn.net/Beeeeeea/article/details/107446371)

hello.c的表示方法说明了一个基本思想：系统中所有的信息——包括磁盘文件、内存中的程序、内存中存放的用户数据以及网络上传送的数据，都是由一串比特表示的。区分不同数据对象的唯一方法是我们读到这些数据对象时的上下文。比如，在不同的上下文中，一个同样的字节序列可能表示一个整数、浮点数、字符串或者机器指令。
作为程序员，我们需要了解数字的机器表示方式，因为它们与实际的整数和实数是不同的。它们是对真值的有限近似值，有时候会有意想不到的行为表现。这方面的基本原理将在第2章中详细描述。

![](读书笔记：深入理解计算机系统(第3版)/10.png)

## 程序被其他程序翻译成不同的格式

hello程序的生命周期是从一个高级C语言程序开始的，因为这种形式能够被人读懂。然而，为了在系统上运行hello.c程序，每条C语句都必须被**其他程序**转化为一系列的低级机器语言指令。然后这些指令按照一种称为**可执行目标程序**的格式打好包，并以**二进制磁盘文件**的形式存放起来。**目标程序也称为可执行目标文件**。

在Unix系统上，从**源文件**到**目标文件**的转化是由**编译器驱动程序**完成的：

~~~c
linux > gcc -o hello hello c
~~~

在这里，GCC编译器驱动程序读取源程序文件hello.c，并把它翻译成一个可执行目标文件hello。这个翻译过程可分为四个阶段完成，如图1-3所示。执行这四个阶段的程序（预处理器、编译器、汇编器和链接器）一起构成了编译系统（compilation system）。

![](读书笔记：深入理解计算机系统(第3版)/11.png)

![](读书笔记：深入理解计算机系统(第3版)/12.png)

> 几个月前我看的时候，不知道是看的太快了还是什么，看不懂，印象不深刻。现在再看，发现自己可以看得懂了，也许是后来又看了几集C语言视频的原因吧。反正随着时间的推移，慢慢的很多东西都会懂了，所以不要因为这本书难懂而放弃，时间会慢慢的让这本书变得好懂的，到时候自己的水平应该也会提高很多了。

![](读书笔记：深入理解计算机系统(第3版)/13.png)

## 了解编译系统如何工作是大有益处的

对于像hello.c这样简单的程序，我们可以依靠编译系统生成正确有效的机器代码。但是，有一些重要的原因促使程序员必须知道编译系统是如何工作的。

* **优化程序性能。**现代编译器都是成熟的工具，通常可以生成很好的代码。作为程序员，我们无须为了写出高效代码而去了解编译器的内部工作。但是，为了在C程序中做出好的编码选择，我们确实需要了解一些机器代码以及编译器将不同的C语句转化为机器代码的方式。比如，一个switch语句是否总是比一系列的if-else语句高效得多？一个函数调用的开销有多大？while循环比for循环更有效吗？指针引用比数组索引更有效吗？为什么将循环求和的结果放到一个本地变量中，会比将其放到一个通过引用传递过来的参数中，运行起来快很多呢？为什么我们只是简单地重新排列一下算术表达式中的括号就能让函数运行得更快？

  ​		在第3章中，我们将介绍x86-64，最近几代Linux，Macintosh和Windows计算机的机器语言。我们会讲述编译器是怎样把不同的C语言结构翻译成这种机器语言的。在第5章中，你将学习如何通过简单转换C语言代码，帮助编译器更好地完成工作，从而调整C程序的性能。在第6章中，你将学习存储器系统的层次结构特性，C语言编译器如何将数组存放在内存中，以及C程序又是如何能够利用这些知识从而更高效地运行。

* **理解链接时出现的错误。**根据我们的经验，一些最令人困扰的程序错误往往都与链接器操作有关，尤其是当你试图构建大型的软件系统时。比如，链接器报告说它无法解析一个引用，这是什么意思？**静态变量和全局变量的区别是什么？**如果你在不同的C文件中定义了名字相同的两个全局变量会发生什么？静态库和动态库的区别是什么？我们在命令行上排列库的顺序有什么影响？最严重的是，为什么有些链接错误直到运行时才会出现？在第7章中，你将得到这些问题的答案。

* **避免安全漏洞。**多年来，缓冲区溢出错误是造成大多数网络和Internet服务器上安全漏洞的主要原因。存在这些错误是因为很少有程序员能够理解需要限制从不受信任的源接收数据的数量和格式。学习安全编程的第一步就是理解数据和控制信息存储在程序栈上的方式会引起的后果。作为学习汇编语言的一部分，我们将在第3章中描述堆栈原理和缓冲区溢出错误。我们还将学习程序员、编译器和操作系统可以用来降低攻击威胁的方法。

## 处理器读并解释储存在内存中的指令

此刻，hello.c源程序已经被编译系统翻译成了可执行目标文件hello，并被存放在磁盘上。要想在Unix系统上运行该可执行文件，我们将它的文件名输入到称为shell的应用程序中：

![](读书笔记：深入理解计算机系统(第3版)/14.png)

shell是一个命令行解释器，它输出一个提示符，等待输入一个命令行，然后执行这个命令。如果该命令行的第一个单词不是一个内置的shell命令，那么shell就会假设这是一个可执行文件的名字，它将加载并运行这个文件。所以在此例中，shell将加载并运行hello程序，然后等待程序终止。hello程序在屏幕上输出它的消息，然后终止。shell随后输出一个提示符，等待下一个输入的命令行。

###  系统的硬件组成

为了理解运行hello程序时发生了什么，我们需要了解一个典型系统的硬件组织，如图1-4所示。这张图是近期Intel系统产品族的模型，但是所有其他系统也有相同的外观和特性。现在不要担心这张图很复杂-我们将在本书分阶段对其进行详尽的介绍。

![](读书笔记：深入理解计算机系统(第3版)/15.png)

**1.总线**

贯穿整个系统的是一组**电子管道**，称作**总线**，它携带信息字节并负责在各个部件间传递。通常总线被设计成传送定长的字节块，也就是字（word）。字中的**字节数（即字长）**是一个基本的系统参数，各个系统中都不尽相同。现在的大多数机器字长要么是4个字节（32位），要么是8个字节（64位），本书中，我们不对字长做任何固定的假设。相反，我们将在需要明确定义的上下文中具体说明一个“字”是多大。

**2.I/O 设备**

I/O（输入/输出）设备是系统与外部世界的联系通道。我们的示例系统包括**四个**I/O设备：**作为用户输入的键盘和鼠标，作为用户输出的显示器，以及用于长期存储数据和程序的磁盘驱动器（简单地说就是磁盘）**。最开始，可执行程序hello就存放在磁盘上。

每个I/O设备都通过一个**控制器或适配器**与I/O总线相连。控制器和适配器之间的**区别**主要在于它们的封装方式。控制器是1/0设备本身或者系统的主印制电路板（通常称作主板）上的芯片组。而适配器则是一块插在主板插槽上的卡。无论如何，它们的**功能都是在I/O总线和I/O设备之间传递信息**。

第6章会更多地说明磁盘之类的I/O设备是如何工作的。在第10章中，你将学习如何在应用程序中利用Unix I/O接口访问设备。我们将特别关注网络类设备，不过这些技术对于其他设备来说也是通用的。

**3.主存**

主存是一个临时存储设备，在处理器执行程序时，用来存放程序和程序处理的数据。从物理上来说，主存是由一组**动态随机存取存储器（DRAM）芯片**组成的。从逻辑上来说，存储器是一个**线性的字节数组**，每个字节都有其**唯一的地址（数组索引）**，这些地址是从零开始的。一般来说，**组成程序的每条机器指令都由不同数量的字节构成**。与C程序变量相对应的数据项的大小是根据类型变化的。比如，在运行Linux的x86-64机器上，short类型的数据需要2个字节，int和float类型需要4个字节，而long和double类型需要8个字节。

第6章将具体介绍存储器技术，比如DRAM芯片是如何工作的，它们又是如何组合起来构成主存的。

**4.处理器**

中央处理单元（CPU），简称处理器，是**解释（或执行）存储在主存中指令的引擎**。处理器的**核心是一个大小为一个字的存储设备（或寄存器），称为程序计数器（PC）**。在任何时刻，**PC都指向主存中的某条机器语言指令（即含有该条指令的地址）**。

> PC也普遍地被用来作为“个人计算机”的缩写。然而，两者之间的区别应该可以很清楚地从上下文中看出来。

从系统通电开始，直到系统断电，**处理器一直在不断地执行程序计数器指向的指令，再更新程序计数器，使其指向下一条指令。**处理器看上去是按照一个非常简单的指令执行模型来操作的，这个模型是由**指令集架构**决定的。在这个模型中，指令按照严格的顺序执行，而执行一条指令包含执行一系列的步骤。处理器从程序计数器指向的内存处读取指令，解释指令中的位，执行该指令指示的简单操作，然后更新PC，使其指向下一条指令，而这条指令并不一定和在内存中刚刚执行的指令相邻。

这样的简单操作并不多，它们围绕着**主存**、**寄存器文件（register file）**和**算术/逻辑单元（ALU）**进行。寄存器文件是一个小的存储设备，由一些单个字长的寄存器组成，每个寄存器都有唯一的名字。ALU计算新的数据和地址值。下面是一些简单操作的例子，CPU在指令的要求下可能会执行这些操作。

![](读书笔记：深入理解计算机系统(第3版)/16.png)

处理器看上去是它的指令集架构的简单实现，但是实际上现代处理器使用了非常复杂的机制来加速程序的执行。因此，我们将处理器的指令集架构和处理器的微体系结构区分开来：指令集架构描述的是每条机器代码指令的效果；而微体系结构描述的是处理器实际上是如何实现的。在第3章研究机器代码时，我们考虑的是机器的指令集架构所提供的抽象性。第4章将更详细地介绍处理器实际上是如何实现的。第5章用一个模型说明现代处理器是如何工作的，从而能预测和优化机器语言程序的性能。

### 运行hello程序

前面简单描述了系统的硬件组成和操作，现在开始介绍当我们运行示例程序时到底发生了些什么。在这里必须省略很多细节，稍后会做补充，但是现在我们将很满意于这种整体上的描述。

初始时，shell程序执行它的指令，等待我们输入一个命令。当我们在键盘上输入字符串"./hello"后，shell程序将字符逐一读入寄存器，再把它存放到内存中，如图1-5所示。

![](读书笔记：深入理解计算机系统(第3版)/17.png)

当我们在键盘上敲回车键时，shell程序就知道我们已经结束了命令的输入。然后shell 执行一系列指令来加载可执行的hello文件，这些指令将hello目标文件中的代码和数据从磁盘复制到主存。数据包括最终会被输出的字符串"hello，world\n"。

利用**直接存储器存取**（**DMA**，将在第6章中讨论）技术，数据可以不通过处理器而直接从磁盘到达主存。这个步骤如图1-6所示。

![](读书笔记：深入理解计算机系统(第3版)/18.png)

一旦目标文件hello中的代码和数据被加载到主存，处理器就开始执行hello程序的main程序中的机器语言指令。这些指令将"hello，world\n"字符串中的字节从主存复制到寄存器文件，再从寄存器文件中复制到显示设备，最终显示在屏幕上。这个步骤如图1-7所示。

![](读书笔记：深入理解计算机系统(第3版)/19.png)

## 高速缓存至关重要

这个简单的示例揭示了一个重要的问题，即**系统花费了大量的时间把信息从一个地方挪到另一个地方**。hello程序的机器指令最初是存放在磁盘上，当程序加载时，它们被复制到主存；当处理器运行程序时，指令又从主存复制到处理器。相似地，数据串"hello，world/n”开始时在磁盘上，然后被复制到主存，最后从主存上复制到显示设备。从程序员的角度来看，**这些复制就是开销**，减慢了程序“**真正**”的工作。因此，系统设计者的一个主要目标就是使这些复制操作尽可能快地完成。

根据**机械原理**，较大的存储设备要比较小的存储设备运行得慢，而快速设备的造价远高于同类的低速设备。比如说，一个典型系统上的磁盘驱动器可能比主存大1000倍，但是对处理器而言，从磁盘驱动器上读取一个字的时间开销要比从主存中读取的开销大1000万倍。

类似地，一个典型的寄存器文件只存储几百字节的信息，而主存里可存放几十亿字节。然而，处理器从寄存器文件中读数据比从主存中读取几乎要快100倍。更麻烦的是，随着这些年半导体技术的进步，这种处理器与主存之间的差距还在持续增大。加快处理器的运行速度比加快主存的运行速度要容易和便宜得多。

针对这种处理器与主存之间的差异，系统设计者采用了更小更快的存储设备，称为**高速缓存存储器（cache memory**，简称为cache或高速缓存），作为暂时的集结区域，存放处理器近期可能会需要的信息。图1-8展示了一个典型系统中的高速缓存存储器。位于处理器芯片上的L1高速缓存的容量可以达到数万字节，访问速度几乎和访问寄存器文件一样快。一个容量为数十万到数百万字节的更大的L2高速缓存通过一条特殊的总线连接到处理器。进程访问L2高速缓存的时间要比访问L1高速缓存的时间长5倍，但是这仍然比访问主存的时间快5~10倍。L1和L2高速缓存是用一种叫做**静态随机访问存储器（SRAM）**的硬件技术实现的。比较新的、处理能力更强大的系统甚至有三级高速缓存：L1，L2和L3，系统可以获得一个很大的存储器，同时访问速度也很快，原因是利用了高速缓存的局部性原理，即程序具有访问局部区域里的数据和代码的趋势。通过**让高速缓存里存放可能经常访问的数据**，**大部分的内存操作都能在快速的高速缓存中完成**。

![](读书笔记：深入理解计算机系统(第3版)/20.png)

本书得出的重要结论之一就是，意识到高速缓存存储器存在的应用程序员能够利用高速缓存将程序的性能提高一个数量级。你将在第6章里学习这些重要的设备以及如何利用它们。

## 存储设备形成层次结构

在处理器和一个较大较慢的设备（例如主存）之间插入一个更小更快的存储设备（例如高速缓存）的想法已经成为一个普遍的观念。实际上，每个计算机系统中的存储设备都被组织成了一个**存储器层次结构**，如图1-9所示。在这个层次结构中，**从上至下，设备的访问速度越来越慢、容量越来越大，并且每字节的造价也越来越便宜**。寄存器文件在层次结构中位于最顶部，也就是第0级或记为L0，这里我们展示的是三层高速缓存L1到L3，占据存储器层次结构的第1层到第3层。主存在第4层，以此类推。

![](读书笔记：深入理解计算机系统(第3版)/21.png)

存储器层次结构的**主要思想**是**上一层的存储器作为低一层存储器的高速缓存**。因此，寄存器文件就是L1的高速缓存，L1是L2的高速缓存，L2是L3的高速缓存，L3是主存的高速缓存，而主存又是磁盘的高速缓存。在某些具有分布式文件系统的网络系统中，本地磁盘就是存储在其他系统中磁盘上的数据的高速缓存。

正如可以运用不同的高速缓存的知识来提高程序性能一样，程序员同样可以利用对整个存储器层次结构的理解来提高程序性能。第6章将更详细地讨论这个问题。

## 操作系统管理硬件

让我们回到hello程序的例子。当shell加载和运行hello程序时，以及hello程序输出自己的消息时，shell和hello程序都没有直接访问键盘、显示器、磁盘或者主存。取而代之的是，它们依靠操作系统提供的服务。我们可以把操作系统看成是应用程序和硬件之间插入的一层软件，如图1-10所示。所有应用程序对硬件的操作尝试都必须通过操作系统。

操作系统有两个基本功能：**(1)防止硬件被失控的应用程序滥用**；**(2)向应用程序提供简单一致的机制来控制复杂而又通常大不相同的低级硬件设备。**操作系统通过几个基本的**抽象概念**（**进程、虚拟内存和文件**）来实现这两个功能。如图1-11所示，**文件是对I/O设备的抽象表示，虚拟内存是对主存和磁盘I/O设备的抽象表示，进程则是对处理器、主存和I/O设备的抽象表示**。我们将依次讨论每种抽象表示。

![](读书笔记：深入理解计算机系统(第3版)/23.png)

> **文件是对I/O设备的抽象表示**
>
> **虚拟内存是对主存和磁盘I/O设备的抽象表示**
>
> **进程则是对处理器、主存和I/O设备的抽象表示**。
>
> 这句话感觉挺重要的，再重新写一遍，加深一下记忆。

![](读书笔记：深入理解计算机系统(第3版)/22.png)

### 进程

像hello这样的程序在现代系统上运行时，操作系统会提供一种**假象**，就好像系统上只有这个程序在运行。程序看上去是独占地使用处理器、主存和I/O设备。处理器看上去就像在不间断地一条接一条地执行程序中的指令，即该程序的代码和数据是系统内存中唯一的对象。**这些假象是通过进程的概念来实现的**，**进程是计算机科学中最重要和最成功的概念之一**。(这句话我还没有深刻的体会到)

**进程是操作系统对一个正在运行的程序的一种抽象**。在一个系统上可以**同时运行多个进程**，而**每个进程都好像在独占地使用硬件。而并发运行**，则是说**一个进程的指令和另一个进程的指令是交错执行的**。在大多数系统中，**需要运行的进程数是多于可以运行它们的CPU个数的**。传统系统在一个时刻只能执行一个程序，而先进的多核处理器同时能够执行多个程序。无论是在单核还是多核系统中，一个CPU看上去都像是在并发地执行多个进程，这是**通过处理器在进程间切换来实现的**。操作系统实现这种交错执行的机制称为**上下文切换**。为了简化讨论，我们只考虑**包含一个CPU**的单处理器系统的情况。我们会在1.9.2节中讨论**多处理器系统**。

操作系统**保持跟踪进程运行所需的所有状态信息**。这种状态，也就是**上下文**，包括许多信息，比如PC和寄存器文件的当前值，以及主存的内容。在任何一个时刻，单处理器系统都只能执行一个进程的代码。**当操作系统决定要把控制权从当前进程转移到某个新进程时，就会进行上下文切换，即保存当前进程的上下文、恢复新进程的上下文，然后将控制权传递到新进程。**新进程就会从它上次停止的地方开始。图1-12展示了示例hello程序运行场景的基本理念。

示例场景中有**两个并发的进程**：**shell进程和hello进程**。最开始，只有shell进程在运行，即等待命令行上的输人。当我们让它运行hello程序时，shell通过调用一个专门的函数，即系统调用，来执行我们的请求，系统调用会将控制权传递给操作系统。操作系统保存shell进程的上下文，创建一个新的hello进程及其上下文，然后将控制权传给新的hello进程。hello进程终止后，操作系统恢复shell进程的上下文，并将控制权传回给它，shell进程会继续等待下一个命令行输入。

如图1-12所示，从一个进程到另一个进程的转换是由**操作系统内核（kernel）**管理的。**内核是操作系统代码常驻主存的部分**。当应用程序需要操作系统的某些操作时，比如读写文件，它就执行一条特殊的**系统调用（system call）**指令，将控制权传递给内核。然后内核执行被请求的操作并返回应用程序。注意，**内核不是一个独立的进程。相反，它是系统管理全部进程所用代码和数据结构的集合**。

![](读书笔记：深入理解计算机系统(第3版)/24.png)

![](读书笔记：深入理解计算机系统(第3版)/25.png)

实现进程这个抽象概念需要低级硬件和操作系统软件之间的紧密合作。我们将在第8章中揭示这项工作的原理，以及应用程序是如何创建和控制它们的进程的。

[如何理解：程序、进程、线程、并发、并行、高并发？](https://www.zhihu.com/question/307100151/answer/894486042)

![](读书笔记：深入理解计算机系统(第3版)/35.png)

### 线程

尽管通常我们认为一个进程只有单一的控制流，但是在现代系统中，**一个进程实际上可以由多个称为线程的执行单元组成，每个线程都运行在进程的上下文中，并共享同样的代码和全局数据**。由于网络服务器中对并行处理的需求，线程成为越来越重要的编程模型，因为多线程之间比多进程之间更容易共享数据，也因为线程一般来说都比进程更高效。当有多处理器可用的时候，多线程也是一种使得程序可以运行得更快的方法，我们将在1.9.2节中讨论这个问题。在第12章中，你将学习并发的基本概念，包括如何写线程化的程序。

### 虚拟内存

虚拟内存是一个抽象概念，**它为每个进程提供了一个假象，即每个进程都在独占地使用主存**。**每个进程看到的内存都是一致的，称为虚拟地址空间**。图1-13所示的是Linux进程的**虚拟地址空间**（其他Unix系统的设计也与此类似）。在Linux中，地址空间最上面的区域是保留给操作系统中的代码和数据的，这对所有进程来说都是一样。地址空间的底部区域存放用户进程定义的代码和数据。请注意，图中的地址是**从下往上增大**的。

![](读书笔记：深入理解计算机系统(第3版)/26.png)

每个进程看到的虚拟地址空间由大量准确定义的区构成，每个区都有专门的功能。在本书的后续章节你将学到更多有关这些区的知识，但是先简单了解每一个区是非常有益的。我们从最低的地址开始，逐步向上介绍。

![](读书笔记：深入理解计算机系统(第3版)/27.png)

虚拟内存的运作需要硬件和操作系统软件之间精密复杂的交互，包括对处理器生成的每个地址的硬件翻译。**基本思想是把一个进程虚拟内存的内容存储在磁盘上，然后用主存作为磁盘的高速缓存。**第9章将解释它如何工作，以及为什么对现代系统的运行如此重要。

### 文件

**文件就是字节序列，仅此而已。**(真的是言简意赅)每个I/O设备，包括磁盘、键盘、显示器，甚至网络，**都可以看成是文件**。系统中的所有输入输出都是通过使用一小组称为Unix I/O的系统函数调用读写文件来实现的。

**文件这个简单而精致的概念是非常强大的**，因为**它向应用程序提供了一个统一的视图，来看待系统中可能含有的所有各式各样的I/O设备**。例如，处理磁盘文件内容的应用程序员可以非常幸福，因为他们无须了解具体的磁盘技术。进一步说，**同一个程序可以在使用不同磁盘技术的不同系统上运行**。你将在第10章中学习Unix I/O。

![](读书笔记：深入理解计算机系统(第3版)/28.png)

## 系统之间利用网络通信

系统漫游至此，我们一直是把系统视为一个孤立的硬件和软件的集合体。实际上，现代系统经常通过网络和其他系统连接到一起。从一个单独的系统来看，网络可视为一个I/O设备，如图1-14所示。当系统从主存复制一串字节到网络适配器时，数据流经过网络到达另一台机器，而不是比如说到达本地磁盘驱动器。相似地，**系统可以读取从其他机器发送来的数据，并把数据复制到自己的主存**。

![](读书笔记：深入理解计算机系统(第3版)/29.png)

随着Internet这样的全球网络的出现，从一台主机复制信息到另外一台主机已经成为计算机系统最重要的用途之一。比如，像电子邮件、即时通信、万维网、FTP和telnet这样的应用都是基于网络复制信息的功能。

回到shell示例，我们可以使用熟悉的telnet应用在一个远程主机上运行hello程序。，假设用本地主机上的telnet客户端连接远程主机上的telnet服务器。在我们登录到远程主机并运行shell后，远端的shell就在等待接收输入命令。此后在远端运行hel10程序包括如图1-15所示的五个基本步骤。

![](读书笔记：深入理解计算机系统(第3版)/30.png)

当我们在telnet客户端键入"hello”字符串并敲下回车键后，客户端软件就会将这个字符串发送到telnet的服务器。telnet服务器从网络上接收到这个字符串后，会把它传递给远端shell程序。接下来，远端shell运行he110程序，并将输出行返回给telnet服务器。最后，telnet服务器通过网络把输出串转发给telnet客户端，客户端就将输出串输出到我们的本地终端上。

这种客户端和服务器之间交互的类型在所有的网络应用中是非常典型的。在第11章中，你将学会如何构造网络应用程序，并利用这些知识创建一个简单的Web服务器。

## 重要主题

### Amdahl定律

![](读书笔记：深入理解计算机系统(第3版)/31.png)

![](读书笔记：深入理解计算机系统(第3版)/32.png)

![](读书笔记：深入理解计算机系统(第3版)/33.png)

### 并发和并行(理解不深)

数字计算机的整个历史中，有两个需求是驱动进步的持续动力：一个是我们想要计算机**做得更多**，另一个是我们想要计算机**运行得更快**。当处理器能够同时做更多的事情时，这两个因素都会改进。我们用的术语**并发(concurrency)**是一个通用的概念，指一个同时具有多个活动的系统；而术语**并行(parallelism)**指的是用并发来使一个系统运行得更快。并行可以在计算机系统的多个抽象层次上运用。在此，我们按照系统层次结构中**由高到低**的顺序重点强调三个层次。

[我已经理解了并发和并行的区别](https://www.cnblogs.com/f-ck-need-u/p/11161481.html)



![](读书笔记：深入理解计算机系统(第3版)/34.png)

**1.线程级并发**

构建在进程这个抽象之上，我们能够**设计出同时有多个程序执行的系统**，这就导致了**并发**。使用线程，我们甚至能够在一个进程中执行多个控制流。自20世纪60年代初期出现时间共享以来，计算机系统中就开始有了对并发执行的支持。传统意义上，**这种并发执行只是模拟出来的**，是**通过使一台计算机在它正在执行的进程间快速切换来实现的，就好像一个杂耍艺人保持多个球在空中飞舞一样**。这种**并发形式允许多个用户同时与系统交互**，例如，当许多人想要从一个web服务器获取页面时。它还允许一个用户同时从事多个任务，例如，在一个窗口中开启Web浏览器，在另一窗口中运行字处理器，同时又播放音乐。在以前，即使处理器必须在多个任务间切换，大多数实际的计算也都是由一个处理器来完成的。这种配置称为**单处理器系统**。

当构建一个由单操作系统内核控制的多处理器组成的系统时，我们就得到了一个**多处理器系统**。其实从20世纪80年代开始，在大规模的计算中就有了这种系统，但是直到最近，随着**多核处理器和超线程（hyperthreading）**的出现，这种系统才变得常见。图1-16给出了这些不同处理器类型的分类。

![](读书笔记：深入理解计算机系统(第3版)/36.png)

多核处理器是将多个CPU（称为“核"）集成到一个集成电路芯片上。图1-17描述的是一个典型多核处理器的组织结构，其中微处理器芯片有4个CPU核，每个核都有自己的L1和L2高速缓存，其中的L1高速缓存分为两个部分-一个保存最近取到的指令，另一个存放数据。这些核共享更高层次的高速缓存，以及到主存的接口。工业界的专家预言他们能够将几十个、最终会是上百个核做到一个芯片上。

![](读书笔记：深入理解计算机系统(第3版)/37.png)

超线程，有时称为**同时多线程（simultaneous multi-threading）**，是一项允许一个CPU执行多个控制流的技术。它涉及CPU某些硬件有多个备份，比如程序计数器和寄存器文件，而其他的硬件部分只有一份，比如执行浮点算术运算的单元。常规的处理器需要大约20000个时钟周期做不同线程间的转换，而超线程的处理器可以在单个周期的基础上决定要执行哪一个线程。这使得CPU能够更好地利用它的处理资源。比如，假设一个线程必须等到某些数据被装载到高速缓存中，那CPU就可以继续去执行另一个线程。举例来说，Intel Core i7处理器可以让每个核执行两个线程，所以一个4核的系统实际上可以并行地执行8个线程。

多处理器的使用可以从两方面提高系统性能。首先，它减少了在执行多个任务时模拟并发的需要。正如前面提到的，即使是只有一个用户使用的个人计算机也需要并发地执行多个活动。其次，它可以使应用程序运行得更快，当然，这必须要求程序是以多线程方式来书写的，这些线程可以并行地高效执行。因此，虽然并发原理的形成和研究已经超过50年的时间了，但是多核和超线程系统的出现才极大地激发了一种愿望，即找到书写应用程序的方法利用硬件开发线程级并行性。第12章会更深入地探讨并发，以及使用并发来提供处理器资源的共享，使程序的执行允许有更多的并行。

**2.指令级并行**

在较低的抽象层次上，**现代处理器可以同时执行多条指令的属性称为指令级并行**。早期的微处理器，如1978年的Intel 8086，需要多个（通常是3~10个）时钟周期来执行一条指令。最近的处理器可以保持每个时钟周期2-4条指令的执行速率。其实每条指令从开始到结束需要长得多的时间，大约20个或者更多周期，但是处理器使用了非常多的聪明技巧来同时处理多达100条指令。在第4章中，我们会研究**流水线（pipelining）**的使用。在流水线中，将执行一条指令所需要的活动划分成不同的步骤，将处理器的硬件组织成一系列的阶段，每个阶段执行一个步骤。这些阶段可以并行地操作，用来处理不同指令的不同部分。我们会看到一个相当简单的硬件设计，它能够达到接近于一个时钟周期一条指令的执行速率。

如果处理器可以达到比一个周期一条指令更快的执行速率，就称之为**超标量（super-scalar）处理器**。大多数现代处理器都支持超标量操作。第5章中，我们将描述超标量处理器的高级模型。应用程序员可以用这个模型来理解程序的性能。然后，他们就能写出拥有更高程度的指令级并行性的程序代码，因而也运行得更快。

**3.单指令、多数据并行**

在最低层次上，许多现代处理器拥有特殊的硬件，允许一条指令产生多个可以并行执行的操作，这种方式称为**单指令、多数据，即SIMD并行**。例如，较新几代的Intel和AMD处理器都具有并行地对8对单精度浮点数（C数据类型float）做加法的指令。

提供这些SIMD指令多是为了提高处理影像、声音和视频数据应用的执行速度。虽然有些编译器会试图从C程序中自动抽取SIMD并行性，但是更可靠的方法是用编译器支持的特殊的向量数据类型来写程序，比如GCC就支持向量数据类型。作为对第5章中比较通用的程序优化描述的补充，我们在网络旁注OPT:SIMD中描述了这种编程方式。

### 计算机系统中抽象的重要性

**抽象的使用是计算机科学中最为重要的概念之一**。例如，为一组函数规定一个简单的应用程序接口（API）就是一个很好的编程习惯，程序员无须了解它内部的工作便可以使用这些代码。不同的编程语言提供不同形式和等级的抽象支持，例如Java类的声明和C语言的函数原型。

我们已经介绍了计算机系统中使用的几个抽象，如图1-18所示。在处理器里，指令集架构提供了对实际处理器硬件的抽象。使用这个抽象，机器代码程序表现得就好像运行在一个一次只执行一条指令的处理器上。底层的硬件远比抽象描述的要复杂精细，它并行地执行多条指令，但又总是与那个简单有序的模型保持一致。只要执行模型一样，不同的处理器实现也能执行同样的机器代码，而又提供不同的开销和性能。

![](读书笔记：深入理解计算机系统(第3版)/38.png)

## 小结

![](读书笔记：深入理解计算机系统(第3版)/39.png)

![](读书笔记：深入理解计算机系统(第3版)/40.png)

# 第一部分：程序结构和执行

我们对计算机系统的探索是从学习计算机本身开始的，它由处理器和存储器子系统组成。在核心部分，我们需要方法来表示基本数据类型，比如整数和实数运算的近似值。然后，我们考虑机器级指令如何操作这样的数据，以及编译器又如何将C程序翻译成这样的指令。接下来，研究几种实现处理器的方法，帮助我们更好地了解硬件资源如何被用来执行指令。一旦理解了编译器和机器级代码，我们就能了解如何通过编写C程序以及编译它们来最大化程序的性能。本部分以存储器子系统的设计作为结束，这是现代计算机系统最复杂的部分之一。

本书的这一部分将领着你深入了解如何表示和执行应用程序。你将学会一些技巧，来帮助你写出安全、可靠且充分利用计算资源的程序。

# 第2章：信息的表示和处理

现代计算机存储和处理的信息以二值信号表示。这些微不足道的二进制数字，或者称为**位（bit）**，形成了数字革命的基础。大家熟悉并使用了1000多年的十进制（以10为基数）起源于印度，在12世纪被阿拉伯数学家改进，并在13世纪被意大利数学家Leonardo Pisano（大约公元1170-1250，更为大家所熟知的名字是Fibonacci）带到西方。对于有10个手指的人类来说，使用十进制表示法是很自然的事情，但是**当构造存储和处理信息的机器时，二进制值工作得更好**。二值信号能够很容易地被表示、存储和传输，例如，可以表示为穿孔卡片上有洞或无洞、导线上的高电压或低电压，或者顺时针或逆时针的磁场。对二值信号进行存储和执行计算的电子电路非常简单和可靠，制造商能够在一个单独的硅片上集成数百万甚至数十亿个这样的电路。

孤立地讲，**单个的位不是非常有用**。然而，当把位**组合**在一起，再加上某种**解释（interpretation）**，即赋予不同的可能位模式以**含义**，我们就能够表示任何有限集合的元素。比如，使用一个**二进制数字系统**，我们能够用位组来编码**非负数**。通过使用标准的字符码，我们能够对文档中的字母和符号进行编码。在本章中，我们将讨论这两种编码，以及负数表示和实数近似值的编码。

我们研究**三种**最重要的数字表示。**无符号（unsigned）**编码基于**传统的二进制表示法**，表示大于或者等于零的数字。**补码（two's-complement）**编码是表示**有符号整数**的最常见的方式，**有符号整数就是可以为正或者为负的数字**。**浮点数（floating-point）**编码是表示**实数的科学记数法的以2为基数的版本**。计算机用这些不同的表示方法实现算术运算，例如加法和乘法，类似于对应的整数和实数运算。

计算机的表示法是**用有限数量的位来对一个数字编码**，因此，当**结果太大以至不能表示**时，某些运算就会**溢出（overflow）**，溢出会导致某些令人吃惊的后果。例如，在今天的大多数计算机上（使用**32位**来表示数据类型int），**计算表达式200*300*400*500会得出结果-884 901 888，这违背了整数运算的特性，计算一组正数的乘积不应产生一个负的结果**。

另一方面，**整数的计算机运算满足人们所熟知的真正整数运算的许多性质**。例如，利用乘法的结合律和交换律，计算下面任何一个C表达式，都会得出结果-884 901 888;

![](读书笔记：深入理解计算机系统(第3版)/41.png)

计算机可能没有产生期望的结果，但是至少它是一致的！

**浮点运算有完全不同的数学属性**。虽然溢出会产生特殊的值十00，但是一组正数的乘积总是正的。由于表示的精度有限，浮点运算是不可结合的。例如，在大多数机器上，c表达式（3.14+1e20）-1e20求得的值会是0.0，而3.14+（1e20-1e20）求得的值会是3.14.

**整数运算和浮点数运算会有不同的数学属性是因为它们处理数字表示有限性的方式不同**——**整数的表示**虽然只能编码一个相对较小的数值范围，但是这种表示是**精确**的；而**浮点数**虽然可以编码一个较大的数值范围，但是这种表示只是**近似**的。

**通过研究数字的实际表示，我们能够了解可以表示的值的范围和不同算术运算的属性**。为了使编写的程序能在全部数值范围内正确工作，而且具有可以跨越不同机器、操作系统和编译器组合的可移植性，了解这种属性是非常重要的。后面我们会讲到，**大量计算机的安全漏洞都是由于计算机算术运算的微妙细节引发的**。在早期，当人们碰巧触发了程序漏洞，只会给人们带来一些不便，但是现在，有众多的黑客企图利用他们能找到的任何漏洞，不经过授权就进入他人的系统。这就要求程序员有更多的责任和义务，去了解他们的程序如何工作，以及如何被迫产生不良的行为。

**计算机用几种不同的二进制表示形式来编码数值**。随着第3章进入机器级编程，你需要熟悉这些表示方式。在本章中，我们描述这些编码，并且教你如何推出数字的表示。通过直接操作数字的位级表示，我们得到了几种进行算术运算的方式。理解这些技术对于理解编译器产生的机器级代码是很重要的，编译器会试图优化算术表达式求值的性能。

我们对这部分内容的处理是**基于一组核心的数学原理的**。从编码的基本定义开始，然后得出一些属性，例如可表示的数字的范围、它们的位级表示以及算术运算的属性。我们相信从这样一个抽象的观点来分析这些内容，对你来说是很重要的，因为**程序员需要对计算机运算与更为人熟悉的整数和实数运算之间的关系有清晰的理解**。

![](读书笔记：深入理解计算机系统(第3版)/42.png)

C++编程语言建立在C语言基础之上，它们使用完全相同的数字表示和运算。本章中关于C的所有内容对C++都有效。另一方面，Java语言创造了一套新的数字表示和运算标准。C标准的设计允许多种实现方式，而Java标准在数据的格式和编码上是非常精确具体的。本章中多处着重介绍了Java支持的表示和运算。

![](读书笔记：深入理解计算机系统(第3版)/43.png)

## 信息存储

大多数计算机使用**8位的块**，或者**字节（byte）**，作为**最小**的**可寻址**的内存单位，而不是访问内存中单独的位。机器级程序将内存视为一个非常大的**字节数组**，称为**虚拟内存（virtual memory）**。内存的**每个字节**都由一个唯一的数字来标识，称为它的**地址（address）**，所有可能**地址的集合就称为虚拟地址空间（virtual address space）**，顾名思义，这个虚拟地址空间只是一个展现给机器级程序的**概念性映像**。实际的实现（见第9章）是将动态随机访问存储器（DRAM）、闪存、磁盘存储器、特殊硬件和操作系统软件结合起来，为程序提供一个看上去统一的字节数组。

在接下来的几章中，我们将讲述**编译器**和**运行时系统**是如何将存储器空间划分为**更可管理的单元**，来存放不同的**程序对象**（program object），即**程序数据、指令和控制信息**。可以用各种机制来分配和管理程序不同部分的存储。这种管理**完全是在虚拟地址空间里完成**的。例如，C语言中一个指针的值（无论它指向一个整数、一个结构或是某个其他程序对象）都是某个存储块的第一个字节的虚拟地址。C编译器还把每个指针和类型信息联系起来，这样就可以根据指针值的类型，生成不同的机器级代码来访问存储在指针所指向位置处的值。尽管C编译器维护着这个类型信息，但是它生成的实际机器级程序并不包含关于数据类型的信息。**每个程序对象可以简单地视为一个字节块，而程序本身就是一个字节序列。**

![](读书笔记：深入理解计算机系统(第3版)/45.png)

### 十六进制表示法

![](读书笔记：深入理解计算机系统(第3版)/46.png)

编写机器级程序的一个常见任务就是在**位模式**的**十进制、二进制和十六进制表示之间人工转换**。二进制和十六进制之间的转换比较简单直接，因为可以一次执行一个十六进制数字的转换。数字的转换可以参考如图2-2所示的表。一个简单的窍门是，记住十六进制数字A，C和F相应的十进制值。而对于把十六进制值B，D和E转换成十进制值，则可以通过计算它们与前三个值的相对关系来完成。

比如，假设给你一个数字0x173A4C，可以**通过展开每个十六进制数字，将它转换为二进制格式**，如下所示：

![](读书笔记：深入理解计算机系统(第3版)/47.png)

![](读书笔记：深入理解计算机系统(第3版)/48.png)

![](读书笔记：深入理解计算机系统(第3版)/49.png)

![](读书笔记：深入理解计算机系统(第3版)/50.png)

![](读书笔记：深入理解计算机系统(第3版)/51.png)

![](读书笔记：深入理解计算机系统(第3版)/52.png)

### 字数据大小

每台计算机都有一个**字长**（word size），指明**指针数据的标称大小**（nominal size）。因为虚拟地址是以这样的一个字来编码的，所以字长决定的最重要的系统参数就是**虚拟地址空间的最大大小**。也就是说，对于一个字长为w位的机器而言，虚拟地址的范围为0~2^w^-1，程序最多访问2^w^个字节。

最近这些年，出现了大规模的**从32位字长机器到64位字长机器的迁移**。这种情况首先出现在为大型科学和数据库应用设计的高端机器上，之后是台式机和笔记本电脑，最近则出现在智能手机的处理器上。32位字长限制虚拟地址空间为4千兆宇节（写作4GB），也就是说，刚刚超过4×10^9^字节。扩展到64位字长使得虚拟地址空间为16EB，大约是1.84×10^19^"字节。

大多数64位机器也可以运行为32位机器编译的程序，这是一种向后兼容。因此，举例来说，当程序prog.c用如下伪指令编译后

~~~javascript
linux> gcc-m32 prog.c
~~~

该程序就可以在32位或64位机器上正确运行。另一方面，若程序用下述伪指令编译

~~~
1inux> gcc-m64 prog.c
~~~

就只在64位机器上运行。因此，我们将程序称为“32位程序”或"64位程序”时，区别在于该程序是**如何编译**的，而不是其**运行的机器类型**。

计算机和编译器支持多种不同方式编码的数字格式，如不同长度的整数和浮点数。比如，许多机器都有处理单个字节的指令，也有处理表示为2字节、4字节或者8字节整数的指令，还有些指令支持表示为4字节和8字节的浮点数。

C语言支持整数和浮点数的多种数据格式。图2-3展示了为C语言各种数据类型分配的字节数。（我们在2.2节讨论C标准保证的字节数和典型的字节数之间的关系。）

![](读书笔记：深入理解计算机系统(第3版)/53.png)

有些数据类型的确切字节数依赖于**程序是如何被编译**的。我们给出的是32位和64位程序的典型值。整数或者为**有符号**的，即可以表示负数、零和正数；或者为**无符号**的，即只能表示非负数。C的数据类型char表示一个单独的字节。尽管"char"是由于它被用来存储文本串中的单个字符这一事实而得名，但它也能被用来存储整数值。数据类型short、int和long可以提供各种数据大小。即使是为64位系统编译，数据类型int通常也只有4个字节。数据类型long一般在32位程序中为4字节，在64位程序中则为8字节。

为了避免由于依赖“典型”大小和不同编译器设置带来的奇怪行为，ISO C99引入了一类**数据类型**，其数据大小是固定的，不随编译器和机器设置而变化。其中就有数据类型int32_t和int64_t，它们分别为4个字节和8个字节。**使用确定大小的整数类型是程序员准确控制数据表示的最佳途径**。

大部分数据类型都编码为有符号数值，除非有前缀关键字unsigned或对确定大小的数据类型使用了特定的无符号声明。数据类型char是一个例外。尽管大多数编译器和机器将它们视为有符号数，但C标准不保证这一点。相反，正如方括号指示的那样，程序员应该用有符号字符的声明来保证其为一个字节的有符号数值。不过，在很多情况下，程序行为对数据类型char是有符号的还是无符号的并不敏感。

对关键字的顺序以及包括还是省略可选关键字来说，C语言允许存在多种形式。比如，下面所有的声明都是一个意思：

~~~c
unsigned long
unsigned long int
long unsigned
long unsigned int
~~~

我们将始终使用图2-3给出的格式。

图2-3还展示了指针（例如一个被声明为类型为"char*”的变量）使用程序的全字长。大多数机器还支持两种不同的浮点数格式：**单精度**（在C中声明为float）和**双精度**（在C中声明为double），这些格式**分别**使用**4字节和8字节**。

![](读书笔记：深入理解计算机系统(第3版)/54.png)

程序员应该力图使他们的程序在不同的机器和编译器上可移植。可移植性的一个方面就是使程序对不同数据类型的确切大小不敏感。C语言标准对不同数据类型的数字范围设置了下界（这点在后面还将讲到），但是却没有上界。因为从1980年左右到2010年左右，32位机器和32位程序是主流的组合，许多程序的编写都假设为图2-3中32位程序的字节分配。随着64位机器的日益普及，在将这些程序移植到新机器上时，许多隐藏的对字长的依赖性就会显现出来，成为错误。比如，许多程序员假设一个声明为int类型的程序对象能被用来存储一个指针。这在大多数32位的机器上能正常工作，但是在一台64位的机器上却会导致问题。

### 寻址和字节顺序

对于跨越多字节的程序对象，我们必须建立两个规则：这个对象的地址是什么，以及在内存中如何排列这些字节。在几乎所有的机器上，多字节对象都被存储为连续的字节序列，对象的地址为所使用字节中最小的地址。例如，假设一个类型为int的变量×的地址为0x100，也就是说，地址表达式&x的值为0x100，那么，（假设数据类型int为32位表示）x的4个字节将被存储在内存的0x100、0x101，0x102和0x103位置。

![](读书笔记：深入理解计算机系统(第3版)/55.png)

注意，在字0x01234567中，高位字节的十六进制值为0x01，而低位字节值为0x67。

大多数Intel兼容机都只用小端模式。另一方面，IBM和Oracle（从其2010年收购Sun Microsystems开始）的大多数机器则是按大端模式操作。注意我们说的是“大多数"。

这些规则并没有严格按照企业界限来划分。比如，IBM和Oracle制造的个人计算机使用的是Intel兼容的处理器，因此使用小端法。许多比较新的微处理器是双端法（birendian），也就是说可以把它们配置成作为大端或者小端的机器运行。然而，实际情况是：一旦选择了特定操作系统，那么字节顺序也就固定下来。比如，用于许多移动电话的ARM微处理器，其硬件可以按小端或大端两种模式操作，但是这些芯片上最常见的两种操作系统——**Android（来自Google）和IOS（来自Apple）——却只能运行于小端模式。**

令人吃惊的是，在哪种字节顺序是合适的这个问题上，人们表现得非常情绪化。实际上，术语"little endian（小端）”和"big endian（大端）”出自Jonathan Swift的《格利佛游记》（Gulliver's Travels）一书，其中交战的两个派别无法就应该从哪一端（小端还是大端）打开一个半熟的鸡蛋达成一致。就像鸡蛋的问题一样，选择何种字节顺序没有技术上的理由，因此争论沦为关于社会政治论题的争论。只要选择了一种规则并且始终如一地坚持，对于哪种字节排序的选择都是任意的。

![](读书笔记：深入理解计算机系统(第3版)/56.png)

对于大多数应用程序员来说，其机器所使用的字节顺序是完全不可见的。无论为哪种类型的机器所编译的程序都会得到同样的结果。不过有时候，字节顺序会成为问题。首先是在不同类型的机器之间通过网络传送二进制数据时，一个常见的问题是当小端法机器产生的数据被发送到大端法机器或者反过来时，接收程序会发现，字里的字节成了反序的。为了避免这类问题，网络应用程序的代码编写必须遵守已建立的关于字节顺序的规则，以确保发送方机器将它的内部表示转换成网络标准，而接收方机器则将网络标准转换为它的内部表示。我们将在第11章中看到这种转换的例子。

**第二种情况**是，当阅读表示整数数据的字节序列时字节顺序也很重要。这通常发生在检查机器级程序时。作为一个示例，从某个文件中摘出了下面这行代码，该文件给出了一个针对Intel x86-64处理器的机器级代码的文本表示：

~~~
4004d3: 01 05 43 Ob 20 00 add %eax,0x200ь43 (%rip)
~~~

这一行是由反汇编器（disassembler）生成的，反汇编器是一种确定可执行程序文件所表示的指令序列的工具。我们将在第3章中学习有关这些工具的更多知识，以及怎样解释像这样的行。而现在，我们只是注意这行表述的意思是：十六进制字节串01 05 43 0b 2000是一条指令的字节级表示，这条指令是把一个字长的数据加到一个值上，该值的存储地址由0x200b43加上当前程序计数器的值得到，当前程序计数器的值即为下一条将要执行指令的地址。如果取出这个序列的最后4个字节：43 0b 20 00，并且按照相反的顺序写出，我们得到00 20 0b43。去掉开头的0，得到值0x200b43，这就是右边的数值。当阅读像此类小端法机器生成的机器级程序表示时，经常会将字节按照相反的顺序显示。书写字节序列的自然方式是最低位字节在左边，而最高位字节在右边，这正好和通常书写数字时最高有效位在左边，最低有效位在右边的方式相反。

字节顺序变得重要的**第三种情况**是当编写规避正常的类型系统的程序时。在C语言中，可以通过使用强制类型转换（cast）或联合（union）来允许以一种数据类型引用一个对象，而这种数据类型与创建这个对象时定义的数据类型不同。大多数应用编程都强烈不推荐这种编码技巧，但是它们对系统级编程来说是非常有用，甚至是必需的。

图2-4展示了一段C代码，它使用强制类型转换来访问和打印不同程序对象的字节表示。我们用typedef将数据类型byte_pointer定义为一个指向类型为"unsigned char"的对象的指针。这样一个字节指针引用一个字节序列，其中每个字节都被认为是一个非负整数。第一个例程show_bytes的输入是一个字节序列的地址，它用一个字节指针以及一个字节数来指示。该字节数指定为数据类型size_t，表示数据结构大小的首选数据类型。show_bytes打印出每个以十六进制表示的字节。C格式化指令"%.2x"表明整数必须用至少两个数字的十六进制格式输出。

![](读书笔记：深入理解计算机系统(第3版)/57.png)

过程show_int，show_	float和show_pointer展示了如何使用程序show_bytes来分别输出类型为int、float和void\*的C程序对象的字节表示。可以观察到它们仅仅传递给show_bytes一个指向它们参数x的指针&x，且这个指针被强制类型转换为"unsigned char*"。这种强制类型转换告诉编译器，程序应该把这个指针看成指向一个字节序列，而不是指向一个原始数据类型的对象。然后，这个指针会被看成是对象使用的最低字节地址。

这些过程使用C语言的运算符sizeof来确定对象使用的字节数。一般来说，表达式sizeof（T）返回存储一个类型为T的对象所需要的字节数。使用sizeof而不是一个固定的值，是向编写在不同机器类型上可移植的代码迈进了一步。

在几种不同的机器上运行如图2-5所示的代码，得到如图2-6所示的结果。我们使用了以下几种机器：

![](读书笔记：深入理解计算机系统(第3版)/58.png)

参数12 345的十六进制表示为0x00003039，对于int类型的数据，除了字节顺序以外，我们在所有机器上都得到相同的结果。特别地，我们可以看到在Linux 32.Windows和Linux64上，最低有效字节值0x39最先输出，这说明它们是小端法机器；而在Sun上最后输出，这说明Sun是大端法机器。同样地，float数据的字节，除了字节顺序以外，也都是相同的。另一方面，指针值却是完全不同的。不同的机器/操作系统配置使用不同的存储分配规则。一个值得注意的特性是Linux 32、Windows和Sun的机器使用4字节地址，而Linux 64使用8字节地址。

![](读书笔记：深入理解计算机系统(第3版)/59.png)

![](读书笔记：深入理解计算机系统(第3版)/60.png)

可以观察到，尽管浮点型和整型数据都是对数值12 345编码，但是它们有截然不同的字节模式：整型为0x00003039，而浮点数为0x4640E400，一般而言，这两种格式使用不同的编码方法。如果我们将这些十六进制模式扩展为二进制形式，并且适当地将它们移位，就会发现一个有13个相匹配的位的序列，用一串星号标识出来：

![](读书笔记：深入理解计算机系统(第3版)/61.png)

这并不是巧合。当我们研究浮点数格式时，还将再回到这个例子。

![](读书笔记：深入理解计算机系统(第3版)/62.png)

![](读书笔记：深入理解计算机系统(第3版)/63.png)

![](读书笔记：深入理解计算机系统(第3版)/64.png)

![](读书笔记：深入理解计算机系统(第3版)/65.png)

### 表示字符串

C语言中字符串被编码为一个以null（其值为0）字符结尾的字符数组。每个字符都由某个标准编码来表示，最常见的是ASCII字符码。因此，如果我们以参数"12345"和6（包括终止符）来运行例程showbytes，我们得到结果31 32 33 34 3500，请注意，十进制数字x的ASCII码正好是0x3x，而终止字节的十六进制表示为0x00。在使用ASCII码作为字符码的任何系统上都将得到相同的结果，与字节顺序和字大小规则无关。因而，**文本数据比二进制数据具有更强的平台独立性**。

![](读书笔记：深入理解计算机系统(第3版)/66.png)

![](读书笔记：深入理解计算机系统(第3版)/67.png)

### 表示代码

考虑下面的C函数：

~~~c
int sum(int x, int y) {
	return x + y;
}
~~~

当我们在示例机器上编译时，生成如下字节表示的机器代码：

![](读书笔记：深入理解计算机系统(第3版)/68.png)

我们发现指令编码是不同的。不同的机器类型使用不同的且不兼容的指令和编码方式。即使是完全一样的进程，运行在不同的操作系统上也会有不同的编码规则，因此二进制代码是不兼容的。二进制代码很少能在不同机器和操作系统组合之间移植。

计算机系统的一个基本概念就是，从机器的角度来看，程序仅仅只是字节序列。机器没有关于原始源程序的任何信息，除了可能有些用来帮助调试的辅助表以外。在第3章学习机器级编程时，我们将更清楚地看到这一点。

### 布尔代数简介



